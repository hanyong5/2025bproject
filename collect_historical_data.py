"""
í•œ ë‹¬ê°„ ê³¼ê±° í•´ì™¸ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ì˜¤ëŠ˜ ì´ì „ 30ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import json
import os
from datetime import datetime, timedelta
from crawlers.market_crawler import crawler


def collect_last_30_days():
    """ì˜¤ëŠ˜ ì´ì „ 30ì¼ê°„ì˜ í•´ì™¸ì‹œì¥ ì§€ìˆ˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘"""
    print("\n" + "="*60)
    print("ğŸ“Š í•œ ë‹¬ê°„ í•´ì™¸ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print("="*60)

    try:
        # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs('data', exist_ok=True)
        print("âœ… data í´ë” í™•ì¸ ì™„ë£Œ")

        # ì˜¤ëŠ˜ ë‚ ì§œ
        today = datetime.now()

        # ìˆ˜ì§‘ ì‹œì‘ì¼ (30ì¼ ì „)
        start_date = today - timedelta(days=30)

        print(f"\nğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {today.strftime('%Y-%m-%d')}")
        print(f"ğŸ“¦ ì´ {31}ì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì˜ˆì •\n")

        success_count = 0
        fail_count = 0

        # 30ì¼ ì „ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ë°˜ë³µ
        for i in range(31):
            current_date = start_date + timedelta(days=i)
            date_str = current_date.strftime('%Y-%m-%d')
            filename = f'data/global_point_{date_str}.json'

            # ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if os.path.exists(filename):
                print(f"â­ï¸  [{i+1}/31] {date_str} - íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                success_count += 1
                continue

            print(f"ğŸ“¥ [{i+1}/31] {date_str} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", end=" ")

            try:
                # ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
                market_data = crawler.get_historical_market_summary(current_date)

                if market_data['total_count'] == 0:
                    print(f"âŒ ë°ì´í„° ì—†ìŒ (ì£¼ë§/íœ´ì¼)")
                    fail_count += 1
                    continue

                # JSON íŒŒì¼ë¡œ ì €ì¥
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(market_data, f, ensure_ascii=False, indent=2)

                file_size = os.path.getsize(filename)
                print(f"âœ… ì €ì¥ ì™„ë£Œ ({market_data['total_count']}ê°œ ì§€ìˆ˜, {file_size} bytes)")
                success_count += 1

            except Exception as e:
                print(f"âŒ ì‹¤íŒ¨: {e}")
                fail_count += 1

        # ê²°ê³¼ ìš”ì•½
        print("\n" + "="*60)
        print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ íŒŒì¼")
        print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ íŒŒì¼")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: data/")
        print("="*60 + "\n")

        # ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ì¶œë ¥
        print("ğŸ“‚ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:")
        files = sorted([f for f in os.listdir('data') if f.startswith('global_point_')])
        for file in files:
            file_path = os.path.join('data', file)
            file_size = os.path.getsize(file_path)
            print(f"  - {file} ({file_size} bytes)")

        print("\nâœ… í•œ ë‹¬ê°„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        return success_count > 0

    except Exception as e:
        print(f"\nâŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("\nğŸŒ ì˜¤ëŠ˜ ì´ì „ 30ì¼ê°„ í•´ì™¸ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘")
    print("âš ï¸  ì´ ì‘ì—…ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì•½ 30ì´ˆ~1ë¶„)\n")

    success = collect_last_30_days()

    if not success:
        print("âš ï¸  ì¼ë¶€ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        exit(1)
    else:
        print("ğŸ‰ ë°ì´í„° ìˆ˜ì§‘ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        exit(0)
